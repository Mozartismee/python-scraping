{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "這段程式碼是用 Python 的 urllib.request 模塊裡的 urlopen 函數從網址 http://pythonscraping.com/pages/page1.html 獲取 HTML 內容。這個網址顯示的是一個簡單的網頁，這段程式碼會抓取這個網頁的 HTML 代碼並將其輸出到 console。\n",
    "\n",
    "\n",
    "1.from urllib.request import urlopen ：這行代碼會導入 Python urllib.request 模塊中的 urlopen 函數。urlopen 函數可以打開一個網頁的 URL 並返回一個 HTTPResponse 物件。\n",
    "\n",
    "2.html = urlopen('http://pythonscraping.com/pages/page1.html')：這行代碼呼叫 urlopen 函數，並將網頁的 URL 傳入。urlopen 函數返回的 HTTPResponse 物件被保存在變數 html 中。\n",
    "\n",
    "3.print(html.read())：這行代碼的作用是讀取 html 變數（HTTPResponse 物件）中的內容，並將讀取到的 HTML 代碼輸出到 console。HTTPResponse 物件的 read() 函數會以字節串（byte string）的形式返回網頁的 HTML 內容。\n",
    "\n",
    "運行此段程式碼將從 http://pythonscraping.com/pages/page1.html 下載並輸出整個 HTML 文件。\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'<html>\\n<head>\\n<title>A Useful Page</title>\\n</head>\\n<body>\\n<h1>An Interesting Title</h1>\\n<div>\\nLorem ipsum dolor sit amet, consectetur adipisicing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.\\n</div>\\n</body>\\n</html>\\n'\n"
     ]
    }
   ],
   "source": [
    "from urllib.request import urlopen\n",
    "\n",
    "html = urlopen('http://pythonscraping.com/pages/page1.html')\n",
    "print(html.read())"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "這段程式碼使用 BeautifulSoup 函式庫來解析從 URL http://www.pythonscraping.com/pages/page1.html 獲取的 HTML 內容，並提取特定標籤（在這個例子中是 <h1> 標籤）的內容並打印出來。這裡的 BeautifulSoup 物件被命名為 bs。\n",
    "\n",
    "程式碼逐行解釋如下：\n",
    "\n",
    "1. from urllib.request import urlopen：導入 urlopen 函數，用於打開 URL 並獲取 HTML 內容。\n",
    "\n",
    "2. from bs4 import BeautifulSoup：導入 BeautifulSoup 函數庫，用於解析 HTML 代碼並操作 DOM 樹。\n",
    "\n",
    "3. html = urlopen('http://www.pythonscraping.com/pages/page1.html')：使用 urlopen 函數打開 URL，並將返回的 HTTPResponse 物件保存在變數 html 中。\n",
    "\n",
    "4. bs = BeautifulSoup(html.read(), 'html.parser')：將 html 物件的內容讀取為字節串，並傳遞給 BeautifulSoup 函數。我們還傳遞了一個 'html.parser' 參數，這表示我們想使用 Python 標準庫內置的 HTML 解析器。這樣，BeauitfulSoup 會將 HTML 代碼解析為 DOM 樹，並把解析後的物件保存為新變數 bs。\n",
    "\n",
    "5. print(bs.h1)：提取 bs 物件（即解析後的 DOM 樹）中的所有 <h1> 標籤，並將其打印到 console。通過使用 bs.h1 或 bs('h1')，BeautifulSoup 會尋找第一個出現在 HTML 文件中的 <h1> 標簽。在這個例子中，它將輸出："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<div>\n",
      "Lorem ipsum dolor sit amet, consectetur adipisicing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.\n",
      "</div>\n"
     ]
    }
   ],
   "source": [
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "html = urlopen('http://www.pythonscraping.com/pages/page1.html')\n",
    "bs = BeautifulSoup(html.read(), 'html.parser')\n",
    "print(bs.div)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The server could not be found!\n"
     ]
    }
   ],
   "source": [
    "from urllib.request import urlopen\n",
    "from urllib.error import HTTPError\n",
    "from urllib.error import URLError\n",
    "\n",
    "try:\n",
    "    html = urlopen(\"https://pythonscrapingthisurldoesnotexist.com\")\n",
    "except HTTPError as e:\n",
    "    print(\"The server returned an HTTP error\")\n",
    "except URLError as e:\n",
    "    print(\"The server could not be found!\")\n",
    "else:\n",
    "    print(html.read())"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "這段程式碼定義了一個名為 getTitle 的函數，用於從給定 URL 的網頁中提取 HTML 中的 <h1> 標籤。如果網頁是可訪問的且 <h1> 標籤存在，則返回標籤內容；否則返回 None。\n",
    "\n",
    "這裡的程式碼首先試圖通過 urlopen(url) 打開給定 URL，如果遇到 HTTPError（例如404 Not Found），則捕獲該異常並返回 None。然後，它會使用 BeautifulSoup 和 lxml 解析器解析網頁的 HTML 內容並提取 <h1> 標籤。若找不到 <h1> 標籤或在提取過程中遇到 AttributeError，則捕獲該異常並返回 None。\n",
    "\n",
    "示例中的 title = getTitle(\"http://www.pythonscraping.com/pages/page1.html\") 調用 getTitle 函數並嘗試從指定的網頁 \"http://www.pythonscraping.com/pages/page1.html\" 提取 <h1> 標籤。如果函數成功提取 title，則將其打印出來；否則打印出 \"Title could not be found\"。\n",
    "\n",
    "在這個例子中，網頁 \"http://www.pythonscraping.com/pages/page1.html\" 是可訪問的且包含 <h1> 標籤，所以程式會輸出:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<h1>An Interesting Title</h1>\n"
     ]
    }
   ],
   "source": [
    "from urllib.request import urlopen\n",
    "from urllib.error import HTTPError\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "\n",
    "def getTitle(url):\n",
    "    try:\n",
    "        html = urlopen(url)\n",
    "    except HTTPError as e:\n",
    "        return None\n",
    "    try:\n",
    "        bsObj = BeautifulSoup(html.read(), \"lxml\")\n",
    "        title = bsObj.body.h1\n",
    "    except AttributeError as e:\n",
    "        return None\n",
    "    return title\n",
    "\n",
    "\n",
    "title = getTitle(\"http://www.pythonscraping.com/pages/page1.html\")\n",
    "if title == None:\n",
    "    print(\"Title could not be found\")\n",
    "else:\n",
    "    print(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
